{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aff1152c-05a5-4a4c-9e2d-f85193289fa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 20:10:54,414 - INFO - Creating necessary directories...\n",
      "2025-05-15 20:10:54,431 - INFO - Loading data from C:\\projects_ml\\Radi_Assist\\data\\raw\\archive\\Data_Entry_2017.csv...\n",
      "2025-05-15 20:10:54,838 - INFO - CSV loaded with 112120 records and columns: ['Image Index', 'Finding Labels', 'Follow-up #', 'Patient ID', 'Patient Age', 'Patient Gender', 'View Position', 'OriginalImage[Width', 'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11']\n",
      "2025-05-15 20:10:54,867 - INFO - Found image folder images_001 with 4999 images\n",
      "2025-05-15 20:10:54,920 - INFO - Found image folder images_002 with 10000 images\n",
      "2025-05-15 20:10:54,975 - INFO - Found image folder images_003 with 10000 images\n",
      "2025-05-15 20:10:55,031 - INFO - Found image folder images_004 with 10000 images\n",
      "2025-05-15 20:10:55,085 - INFO - Found image folder images_005 with 10000 images\n",
      "2025-05-15 20:10:55,138 - INFO - Found image folder images_006 with 10000 images\n",
      "2025-05-15 20:10:55,188 - INFO - Found image folder images_007 with 10000 images\n",
      "2025-05-15 20:10:55,242 - INFO - Found image folder images_008 with 10000 images\n",
      "2025-05-15 20:10:55,295 - INFO - Found image folder images_009 with 10000 images\n",
      "2025-05-15 20:10:55,349 - INFO - Found image folder images_010 with 10000 images\n",
      "2025-05-15 20:10:55,403 - INFO - Found image folder images_011 with 10000 images\n",
      "2025-05-15 20:10:55,437 - INFO - Found image folder images_012 with 7121 images\n",
      "2025-05-15 20:10:55,443 - INFO - Current images per class:\n",
      "2025-05-15 20:10:55,445 - INFO - - Atelectasis: 0\n",
      "2025-05-15 20:10:55,446 - INFO - - Cardiomegaly: 0\n",
      "2025-05-15 20:10:55,448 - INFO - - Effusion: 0\n",
      "2025-05-15 20:10:55,448 - INFO - - Infiltration: 0\n",
      "2025-05-15 20:10:55,450 - INFO - - Mass: 0\n",
      "2025-05-15 20:10:55,451 - INFO - - Nodule: 0\n",
      "2025-05-15 20:10:55,453 - INFO - - Pneumonia: 0\n",
      "2025-05-15 20:10:55,454 - INFO - - Pneumothorax: 0\n",
      "2025-05-15 20:10:55,456 - INFO - - Consolidation: 0\n",
      "2025-05-15 20:10:55,457 - INFO - - Edema: 0\n",
      "2025-05-15 20:10:55,459 - INFO - - Emphysema: 0\n",
      "2025-05-15 20:10:55,460 - INFO - - Fibrosis: 0\n",
      "2025-05-15 20:10:55,461 - INFO - - Pleural_Thickening: 0\n",
      "2025-05-15 20:10:55,463 - INFO - - Hernia: 0\n",
      "2025-05-15 20:10:55,464 - WARNING - No images found in augmented folders. Check if images were copied correctly.\n",
      "2025-05-15 20:10:55,465 - INFO - Attempting to copy original images to augmented folders...\n",
      "Copying original images:   1%|▋                                                                                      | 852/112120 [00:04<07:38, 242.70it/s]2025-05-15 20:10:59,961 - INFO - Copied 500 images so far...\n",
      "Copying original images:   2%|█▍                                                                                    | 1947/112120 [00:09<07:19, 250.58it/s]2025-05-15 20:11:05,291 - INFO - Copied 1000 images so far...\n",
      "Copying original images:   3%|██▍                                                                                   | 3174/112120 [00:15<10:29, 173.15it/s]2025-05-15 20:11:11,267 - INFO - Copied 1500 images so far...\n",
      "Copying original images:   4%|███▍                                                                                  | 4432/112120 [00:19<04:24, 406.92it/s]2025-05-15 20:11:14,976 - INFO - Copied 2000 images so far...\n",
      "Copying original images:   5%|████▎                                                                                 | 5571/112120 [00:22<03:54, 454.46it/s]2025-05-15 20:11:17,682 - INFO - Copied 2500 images so far...\n",
      "Copying original images:   6%|█████▎                                                                                | 6870/112120 [00:25<05:26, 322.50it/s]2025-05-15 20:11:20,979 - INFO - Copied 3000 images so far...\n",
      "Copying original images:   7%|██████▏                                                                               | 8013/112120 [00:28<05:17, 327.57it/s]2025-05-15 20:11:24,078 - INFO - Copied 3500 images so far...\n",
      "Copying original images:   8%|███████                                                                               | 9284/112120 [00:32<07:40, 223.53it/s]2025-05-15 20:11:28,434 - INFO - Copied 4000 images so far...\n",
      "Copying original images:   9%|███████▉                                                                             | 10489/112120 [00:36<05:47, 292.14it/s]2025-05-15 20:11:32,070 - INFO - Copied 4500 images so far...\n",
      "Copying original images:  10%|████████▉                                                                            | 11752/112120 [00:41<08:44, 191.22it/s]2025-05-15 20:11:37,369 - INFO - Copied 5000 images so far...\n",
      "Copying original images:  12%|█████████▉                                                                           | 13072/112120 [00:46<08:50, 186.82it/s]2025-05-15 20:11:42,106 - INFO - Copied 5500 images so far...\n",
      "Copying original images:  13%|██████████▊                                                                          | 14329/112120 [00:50<03:45, 433.33it/s]2025-05-15 20:11:46,339 - INFO - Copied 6000 images so far...\n",
      "Copying original images:  14%|███████████▊                                                                         | 15555/112120 [00:55<06:39, 242.02it/s]2025-05-15 20:11:50,645 - INFO - Copied 6500 images so far...\n",
      "Copying original images:  15%|████████████▋                                                                        | 16769/112120 [01:00<04:58, 319.81it/s]2025-05-15 20:11:55,812 - INFO - Copied 7000 images so far...\n",
      "Copying original images:  16%|█████████████▋                                                                       | 18084/112120 [01:05<08:41, 180.18it/s]2025-05-15 20:12:01,426 - INFO - Copied 7500 images so far...\n",
      "Copying original images:  17%|██████████████▌                                                                      | 19213/112120 [01:10<04:26, 349.04it/s]2025-05-15 20:12:06,531 - INFO - Copied 8000 images so far...\n",
      "Copying original images:  18%|███████████████▌                                                                     | 20467/112120 [01:16<09:19, 163.91it/s]2025-05-15 20:12:12,476 - INFO - Copied 8500 images so far...\n",
      "Copying original images:  19%|████████████████▎                                                                    | 21483/112120 [01:22<05:49, 259.34it/s]2025-05-15 20:12:18,308 - INFO - Copied 9000 images so far...\n",
      "Copying original images:  20%|█████████████████▏                                                                   | 22722/112120 [01:26<04:09, 358.99it/s]2025-05-15 20:12:21,861 - INFO - Copied 9500 images so far...\n",
      "Copying original images:  21%|██████████████████▏                                                                  | 23975/112120 [01:30<07:12, 203.84it/s]2025-05-15 20:12:26,270 - INFO - Copied 10000 images so far...\n",
      "Copying original images:  22%|███████████████████                                                                  | 25178/112120 [01:34<04:32, 318.94it/s]2025-05-15 20:12:30,036 - INFO - Copied 10500 images so far...\n",
      "Copying original images:  23%|███████████████████▉                                                                 | 26321/112120 [01:38<06:41, 213.47it/s]2025-05-15 20:12:34,281 - INFO - Copied 11000 images so far...\n",
      "Copying original images:  24%|████████████████████▊                                                                | 27442/112120 [01:43<05:58, 236.09it/s]2025-05-15 20:12:38,739 - INFO - Copied 11500 images so far...\n",
      "Copying original images:  26%|█████████████████████▊                                                               | 28762/112120 [01:47<05:27, 254.57it/s]2025-05-15 20:12:43,538 - INFO - Copied 12000 images so far...\n",
      "Copying original images:  27%|██████████████████████▋                                                              | 29923/112120 [01:51<03:57, 346.41it/s]2025-05-15 20:12:47,156 - INFO - Copied 12500 images so far...\n",
      "Copying original images:  28%|███████████████████████▌                                                             | 31079/112120 [01:55<04:55, 274.42it/s]2025-05-15 20:12:51,095 - INFO - Copied 13000 images so far...\n",
      "Copying original images:  29%|████████████████████████▍                                                            | 32280/112120 [01:59<03:32, 376.20it/s]2025-05-15 20:12:54,861 - INFO - Copied 13500 images so far...\n",
      "Copying original images:  30%|█████████████████████████▎                                                           | 33390/112120 [02:04<05:05, 257.35it/s]2025-05-15 20:12:59,494 - INFO - Copied 14000 images so far...\n",
      "Copying original images:  31%|██████████████████████████▎                                                          | 34653/112120 [02:08<02:39, 486.98it/s]2025-05-15 20:13:03,535 - INFO - Copied 14500 images so far...\n",
      "Copying original images:  32%|███████████████████████████                                                          | 35736/112120 [02:11<03:36, 352.69it/s]2025-05-15 20:13:06,543 - INFO - Copied 15000 images so far...\n",
      "Copying original images:  33%|████████████████████████████                                                         | 36948/112120 [02:13<02:57, 424.01it/s]2025-05-15 20:13:09,501 - INFO - Copied 15500 images so far...\n",
      "Copying original images:  34%|████████████████████████████▊                                                        | 37998/112120 [02:17<03:37, 341.48it/s]2025-05-15 20:13:12,978 - INFO - Copied 16000 images so far...\n",
      "Copying original images:  35%|█████████████████████████████▌                                                       | 39004/112120 [02:20<02:56, 413.37it/s]2025-05-15 20:13:15,805 - INFO - Copied 16500 images so far...\n",
      "Copying original images:  36%|██████████████████████████████▍                                                      | 40199/112120 [02:23<02:46, 432.95it/s]2025-05-15 20:13:18,848 - INFO - Copied 17000 images so far...\n",
      "Copying original images:  37%|███████████████████████████████▎                                                     | 41364/112120 [02:26<03:38, 324.12it/s]2025-05-15 20:13:21,841 - INFO - Copied 17500 images so far...\n",
      "Copying original images:  38%|████████████████████████████████                                                     | 42355/112120 [02:29<02:59, 389.56it/s]2025-05-15 20:13:24,784 - INFO - Copied 18000 images so far...\n",
      "Copying original images:  39%|█████████████████████████████████                                                    | 43559/112120 [02:32<03:19, 343.09it/s]2025-05-15 20:13:27,848 - INFO - Copied 18500 images so far...\n",
      "Copying original images:  40%|█████████████████████████████████▊                                                   | 44587/112120 [02:35<03:42, 303.10it/s]2025-05-15 20:13:30,785 - INFO - Copied 19000 images so far...\n",
      "Copying original images:  41%|██████████████████████████████████▋                                                  | 45712/112120 [02:38<04:04, 271.80it/s]2025-05-15 20:13:33,865 - INFO - Copied 19500 images so far...\n",
      "Copying original images:  42%|███████████████████████████████████▍                                                 | 46824/112120 [02:41<03:04, 353.16it/s]2025-05-15 20:13:36,959 - INFO - Copied 20000 images so far...\n",
      "Copying original images:  43%|████████████████████████████████████▏                                                | 47783/112120 [02:44<03:26, 311.53it/s]2025-05-15 20:13:40,093 - INFO - Copied 20500 images so far...\n",
      "Copying original images:  44%|█████████████████████████████████████▏                                               | 49042/112120 [02:47<02:40, 392.51it/s]2025-05-15 20:13:43,240 - INFO - Copied 21000 images so far...\n",
      "Copying original images:  45%|██████████████████████████████████████                                               | 50202/112120 [02:50<02:40, 386.18it/s]2025-05-15 20:13:46,394 - INFO - Copied 21500 images so far...\n",
      "Copying original images:  46%|██████████████████████████████████████▊                                              | 51185/112120 [02:53<02:30, 404.37it/s]2025-05-15 20:13:49,441 - INFO - Copied 22000 images so far...\n",
      "Copying original images:  47%|███████████████████████████████████████▋                                             | 52290/112120 [02:57<02:01, 491.16it/s]2025-05-15 20:13:52,585 - INFO - Copied 22500 images so far...\n",
      "Copying original images:  48%|████████████████████████████████████████▍                                            | 53277/112120 [03:00<03:22, 290.31it/s]2025-05-15 20:13:55,919 - INFO - Copied 23000 images so far...\n",
      "Copying original images:  48%|█████████████████████████████████████████▏                                           | 54375/112120 [03:03<03:03, 314.62it/s]2025-05-15 20:13:59,058 - INFO - Copied 23500 images so far...\n",
      "Copying original images:  49%|█████████████████████████████████████████▉                                           | 55360/112120 [03:06<02:50, 333.12it/s]2025-05-15 20:14:02,161 - INFO - Copied 24000 images so far...\n",
      "Copying original images:  50%|██████████████████████████████████████████▋                                          | 56246/112120 [03:09<03:55, 236.89it/s]2025-05-15 20:14:05,467 - INFO - Copied 24500 images so far...\n",
      "Copying original images:  51%|███████████████████████████████████████████▍                                         | 57328/112120 [03:13<02:18, 396.41it/s]2025-05-15 20:14:08,626 - INFO - Copied 25000 images so far...\n",
      "Copying original images:  52%|████████████████████████████████████████████▎                                        | 58425/112120 [03:16<01:57, 456.27it/s]2025-05-15 20:14:11,831 - INFO - Copied 25500 images so far...\n",
      "Copying original images:  53%|█████████████████████████████████████████████                                        | 59496/112120 [03:19<02:42, 324.44it/s]2025-05-15 20:14:15,083 - INFO - Copied 26000 images so far...\n",
      "Copying original images:  54%|█████████████████████████████████████████████▉                                       | 60554/112120 [03:22<02:09, 397.43it/s]2025-05-15 20:14:18,286 - INFO - Copied 26500 images so far...\n",
      "Copying original images:  55%|██████████████████████████████████████████████▋                                      | 61651/112120 [03:25<02:25, 346.15it/s]2025-05-15 20:14:21,454 - INFO - Copied 27000 images so far...\n",
      "Copying original images:  56%|███████████████████████████████████████████████▌                                     | 62762/112120 [03:29<02:48, 293.00it/s]2025-05-15 20:14:24,598 - INFO - Copied 27500 images so far...\n",
      "Copying original images:  57%|████████████████████████████████████████████████▎                                    | 63740/112120 [03:32<01:58, 406.81it/s]2025-05-15 20:14:27,789 - INFO - Copied 28000 images so far...\n",
      "Copying original images:  58%|█████████████████████████████████████████████████▏                                   | 64822/112120 [03:35<02:08, 366.81it/s]2025-05-15 20:14:30,901 - INFO - Copied 28500 images so far...\n",
      "Copying original images:  59%|█████████████████████████████████████████████████▉                                   | 65919/112120 [03:38<02:21, 326.82it/s]2025-05-15 20:14:34,264 - INFO - Copied 29000 images so far...\n",
      "Copying original images:  60%|██████████████████████████████████████████████████▊                                  | 66950/112120 [03:41<02:02, 367.47it/s]2025-05-15 20:14:37,455 - INFO - Copied 29500 images so far...\n",
      "Copying original images:  61%|███████████████████████████████████████████████████▍                                 | 67909/112120 [03:45<03:09, 233.06it/s]2025-05-15 20:14:40,814 - INFO - Copied 30000 images so far...\n",
      "Copying original images:  62%|████████████████████████████████████████████████████▎                                | 68966/112120 [03:48<02:22, 303.06it/s]2025-05-15 20:14:44,027 - INFO - Copied 30500 images so far...\n",
      "Copying original images:  62%|█████████████████████████████████████████████████████                                | 69926/112120 [03:51<01:54, 369.23it/s]2025-05-15 20:14:47,327 - INFO - Copied 31000 images so far...\n",
      "Copying original images:  63%|█████████████████████████████████████████████████████▊                               | 70921/112120 [03:55<01:40, 408.55it/s]2025-05-15 20:14:50,783 - INFO - Copied 31500 images so far...\n",
      "Copying original images:  64%|██████████████████████████████████████████████████████▍                              | 71885/112120 [03:58<02:24, 278.43it/s]2025-05-15 20:14:54,071 - INFO - Copied 32000 images so far...\n",
      "Copying original images:  65%|███████████████████████████████████████████████████████▎                             | 73004/112120 [04:01<01:58, 330.60it/s]2025-05-15 20:14:57,370 - INFO - Copied 32500 images so far...\n",
      "Copying original images:  66%|████████████████████████████████████████████████████████                             | 73998/112120 [04:04<01:58, 322.83it/s]2025-05-15 20:15:00,546 - INFO - Copied 33000 images so far...\n",
      "Copying original images:  67%|████████████████████████████████████████████████████████▊                            | 74934/112120 [04:08<02:15, 273.52it/s]2025-05-15 20:15:04,101 - INFO - Copied 33500 images so far...\n",
      "Copying original images:  68%|█████████████████████████████████████████████████████████▌                           | 75926/112120 [04:11<01:52, 322.60it/s]2025-05-15 20:15:07,448 - INFO - Copied 34000 images so far...\n",
      "Copying original images:  69%|██████████████████████████████████████████████████████████▎                          | 76882/112120 [04:15<02:20, 251.33it/s]2025-05-15 20:15:10,651 - INFO - Copied 34500 images so far...\n",
      "Copying original images:  69%|██████████████████████████████████████████████████████████▉                          | 77795/112120 [04:18<02:06, 271.32it/s]2025-05-15 20:15:13,823 - INFO - Copied 35000 images so far...\n",
      "Copying original images:  70%|███████████████████████████████████████████████████████████▋                         | 78738/112120 [04:21<01:57, 284.07it/s]2025-05-15 20:15:17,092 - INFO - Copied 35500 images so far...\n",
      "Copying original images:  71%|████████████████████████████████████████████████████████████▍                        | 79686/112120 [04:24<01:41, 321.07it/s]2025-05-15 20:15:20,271 - INFO - Copied 36000 images so far...\n",
      "Copying original images:  72%|█████████████████████████████████████████████████████████████                        | 80616/112120 [04:27<01:55, 272.18it/s]2025-05-15 20:15:23,460 - INFO - Copied 36500 images so far...\n",
      "Copying original images:  73%|█████████████████████████████████████████████████████████████▊                       | 81588/112120 [04:31<01:27, 347.47it/s]2025-05-15 20:15:26,669 - INFO - Copied 37000 images so far...\n",
      "Copying original images:  74%|██████████████████████████████████████████████████████████████▌                      | 82525/112120 [04:34<01:34, 313.31it/s]2025-05-15 20:15:29,865 - INFO - Copied 37500 images so far...\n",
      "Copying original images:  74%|███████████████████████████████████████████████████████████████▏                     | 83344/112120 [04:37<01:50, 259.43it/s]2025-05-15 20:15:33,010 - INFO - Copied 38000 images so far...\n",
      "Copying original images:  75%|███████████████████████████████████████████████████████████████▉                     | 84312/112120 [04:40<01:38, 282.47it/s]2025-05-15 20:15:36,335 - INFO - Copied 38500 images so far...\n",
      "Copying original images:  76%|████████████████████████████████████████████████████████████████▋                    | 85368/112120 [04:43<01:26, 309.21it/s]2025-05-15 20:15:39,509 - INFO - Copied 39000 images so far...\n",
      "Copying original images:  77%|█████████████████████████████████████████████████████████████████▍                   | 86297/112120 [04:47<01:24, 304.22it/s]2025-05-15 20:15:42,813 - INFO - Copied 39500 images so far...\n",
      "Copying original images:  78%|██████████████████████████████████████████████████████████████████                   | 87153/112120 [04:50<01:22, 304.06it/s]2025-05-15 20:15:46,047 - INFO - Copied 40000 images so far...\n",
      "Copying original images:  79%|██████████████████████████████████████████████████████████████████▊                  | 88159/112120 [04:53<01:40, 238.87it/s]2025-05-15 20:15:49,429 - INFO - Copied 40500 images so far...\n",
      "Copying original images:  79%|███████████████████████████████████████████████████████████████████▌                 | 89132/112120 [04:57<01:15, 303.24it/s]2025-05-15 20:15:52,573 - INFO - Copied 41000 images so far...\n",
      "Copying original images:  80%|████████████████████████████████████████████████████████████████████▎                | 90166/112120 [05:00<01:15, 291.38it/s]2025-05-15 20:15:55,794 - INFO - Copied 41500 images so far...\n",
      "Copying original images:  81%|█████████████████████████████████████████████████████████████████████                | 91065/112120 [05:03<01:08, 308.98it/s]2025-05-15 20:15:59,019 - INFO - Copied 42000 images so far...\n",
      "Copying original images:  82%|█████████████████████████████████████████████████████████████████████▊               | 92036/112120 [05:06<01:01, 326.06it/s]2025-05-15 20:16:02,150 - INFO - Copied 42500 images so far...\n",
      "Copying original images:  83%|██████████████████████████████████████████████████████████████████████▍              | 92931/112120 [05:09<01:18, 245.21it/s]2025-05-15 20:16:05,376 - INFO - Copied 43000 images so far...\n",
      "Copying original images:  85%|████████████████████████████████████████████████████████████████████████▎            | 95397/112120 [05:13<00:23, 724.18it/s]2025-05-15 20:16:08,985 - INFO - Copied 43500 images so far...\n",
      "Copying original images:  86%|█████████████████████████████████████████████████████████████████████████            | 96444/112120 [05:16<00:48, 321.43it/s]2025-05-15 20:16:12,284 - INFO - Copied 44000 images so far...\n",
      "Copying original images:  87%|█████████████████████████████████████████████████████████████████████████▊           | 97413/112120 [05:20<00:53, 275.50it/s]2025-05-15 20:16:15,547 - INFO - Copied 44500 images so far...\n",
      "Copying original images:  88%|██████████████████████████████████████████████████████████████████████████▌          | 98393/112120 [05:23<00:37, 362.57it/s]2025-05-15 20:16:18,727 - INFO - Copied 45000 images so far...\n",
      "Copying original images:  89%|███████████████████████████████████████████████████████████████████████████▎         | 99340/112120 [05:26<00:35, 359.07it/s]2025-05-15 20:16:21,811 - INFO - Copied 45500 images so far...\n",
      "Copying original images:  89%|███████████████████████████████████████████████████████████████████████████▏        | 100309/112120 [05:29<00:42, 280.15it/s]2025-05-15 20:16:24,949 - INFO - Copied 46000 images so far...\n",
      "Copying original images:  90%|███████████████████████████████████████████████████████████████████████████▉        | 101347/112120 [05:32<00:34, 313.15it/s]2025-05-15 20:16:28,080 - INFO - Copied 46500 images so far...\n",
      "Copying original images:  91%|████████████████████████████████████████████████████████████████████████████▋       | 102355/112120 [05:35<00:29, 336.04it/s]2025-05-15 20:16:31,170 - INFO - Copied 47000 images so far...\n",
      "Copying original images:  92%|█████████████████████████████████████████████████████████████████████████████▍      | 103357/112120 [05:38<00:27, 313.74it/s]2025-05-15 20:16:34,405 - INFO - Copied 47500 images so far...\n",
      "Copying original images:  93%|██████████████████████████████████████████████████████████████████████████████▏     | 104312/112120 [05:42<00:23, 337.28it/s]2025-05-15 20:16:37,768 - INFO - Copied 48000 images so far...\n",
      "Copying original images:  94%|██████████████████████████████████████████████████████████████████████████████▉     | 105422/112120 [05:45<00:19, 337.78it/s]2025-05-15 20:16:41,263 - INFO - Copied 48500 images so far...\n",
      "Copying original images:  95%|███████████████████████████████████████████████████████████████████████████████▋    | 106408/112120 [05:49<00:19, 290.56it/s]2025-05-15 20:16:44,783 - INFO - Copied 49000 images so far...\n",
      "Copying original images:  96%|████████████████████████████████████████████████████████████████████████████████▍   | 107397/112120 [05:52<00:16, 286.47it/s]2025-05-15 20:16:48,169 - INFO - Copied 49500 images so far...\n",
      "Copying original images:  97%|█████████████████████████████████████████████████████████████████████████████████▎  | 108485/112120 [05:56<00:10, 331.54it/s]2025-05-15 20:16:51,535 - INFO - Copied 50000 images so far...\n",
      "Copying original images:  98%|██████████████████████████████████████████████████████████████████████████████████  | 109497/112120 [05:59<00:08, 301.81it/s]2025-05-15 20:16:54,825 - INFO - Copied 50500 images so far...\n",
      "Copying original images:  98%|██████████████████████████████████████████████████████████████████████████████████▋ | 110415/112120 [06:02<00:05, 312.97it/s]2025-05-15 20:16:58,130 - INFO - Copied 51000 images so far...\n",
      "Copying original images:  99%|███████████████████████████████████████████████████████████████████████████████████▌| 111521/112120 [06:06<00:01, 327.46it/s]2025-05-15 20:17:01,743 - INFO - Copied 51500 images so far...\n",
      "Copying original images: 100%|████████████████████████████████████████████████████████████████████████████████████| 112120/112120 [06:08<00:00, 304.64it/s]\n",
      "2025-05-15 20:17:03,522 - INFO - Copied 51759 original images to augmented folders\n",
      "2025-05-15 20:17:03,524 - INFO - - Atelectasis: 11545\n",
      "2025-05-15 20:17:03,524 - INFO - - Cardiomegaly: 2404\n",
      "2025-05-15 20:17:03,525 - INFO - - Effusion: 8040\n",
      "2025-05-15 20:17:03,528 - INFO - - Infiltration: 11795\n",
      "2025-05-15 20:17:03,530 - INFO - - Mass: 2926\n",
      "2025-05-15 20:17:03,532 - INFO - - Nodule: 3009\n",
      "2025-05-15 20:17:03,533 - INFO - - Pneumonia: 325\n",
      "2025-05-15 20:17:03,534 - INFO - - Pneumothorax: 2200\n",
      "2025-05-15 20:17:03,538 - INFO - - Consolidation: 3331\n",
      "2025-05-15 20:17:03,540 - INFO - - Edema: 1862\n",
      "2025-05-15 20:17:03,543 - INFO - - Emphysema: 1734\n",
      "2025-05-15 20:17:03,547 - INFO - - Fibrosis: 1215\n",
      "2025-05-15 20:17:03,549 - INFO - - Pleural_Thickening: 1217\n",
      "2025-05-15 20:17:03,551 - INFO - - Hernia: 156\n",
      "2025-05-15 20:17:03,552 - INFO - Starting image augmentation with target of 12000 images per class...\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_38992\\3266818677.py:49: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2)\n",
      "2025-05-15 20:17:04,178 - INFO - Found 11545 original images for Atelectasis\n",
      "2025-05-15 20:17:04,180 - INFO - Need to create 455 more images for Atelectasis\n",
      "2025-05-15 20:17:04,182 - INFO - Will create 1 augmentations per original image\n",
      "Augmenting Atelectasis:   4%|███▌                                                                                      | 455/11545 [00:31<12:44, 14.51it/s]\n",
      "2025-05-15 20:17:35,545 - INFO - Created 455 augmented images for Atelectasis. Total count: 12000/12000\n",
      "2025-05-15 20:17:35,546 - INFO - Final count for Atelectasis: 12000/12000\n",
      "2025-05-15 20:17:35,634 - INFO - Found 2404 original images for Cardiomegaly\n",
      "2025-05-15 20:17:35,636 - INFO - Need to create 9596 more images for Cardiomegaly\n",
      "2025-05-15 20:17:35,636 - INFO - Will create 4 augmentations per original image\n",
      "Augmenting Cardiomegaly: 100%|████████████████████████████████████████████████████████████████████████████████████████▊| 2399/2404 [06:09<00:00,  6.49it/s]\n",
      "2025-05-15 20:23:45,389 - INFO - Created 9596 augmented images for Cardiomegaly. Total count: 12000/12000\n",
      "2025-05-15 20:23:45,391 - INFO - Final count for Cardiomegaly: 12000/12000\n",
      "2025-05-15 20:23:45,874 - INFO - Found 8040 original images for Effusion\n",
      "2025-05-15 20:23:45,878 - INFO - Need to create 3960 more images for Effusion\n",
      "2025-05-15 20:23:45,881 - INFO - Will create 1 augmentations per original image\n",
      "Augmenting Effusion:  49%|█████████████████████████████████████████████▊                                               | 3960/8040 [04:11<04:18, 15.77it/s]\n",
      "2025-05-15 20:27:57,011 - INFO - Created 3960 augmented images for Effusion. Total count: 12000/12000\n",
      "2025-05-15 20:27:57,016 - INFO - Final count for Effusion: 12000/12000\n",
      "2025-05-15 20:27:57,651 - INFO - Found 11795 original images for Infiltration\n",
      "2025-05-15 20:27:57,656 - INFO - Need to create 205 more images for Infiltration\n",
      "2025-05-15 20:27:57,661 - INFO - Will create 1 augmentations per original image\n",
      "Augmenting Infiltration:   2%|█▌                                                                                       | 205/11795 [00:14<13:30, 14.30it/s]\n",
      "2025-05-15 20:28:12,018 - INFO - Created 205 augmented images for Infiltration. Total count: 12000/12000\n",
      "2025-05-15 20:28:12,021 - INFO - Final count for Infiltration: 12000/12000\n",
      "2025-05-15 20:28:12,125 - INFO - Found 2926 original images for Mass\n",
      "2025-05-15 20:28:12,128 - INFO - Need to create 9074 more images for Mass\n",
      "2025-05-15 20:28:12,131 - INFO - Will create 4 augmentations per original image\n",
      "Augmenting Mass:  78%|███████████████████████████████████████████████████████████████████████████▏                     | 2269/2926 [05:27<01:34,  6.93it/s]\n",
      "2025-05-15 20:33:39,588 - INFO - Created 9074 augmented images for Mass. Total count: 12000/12000\n",
      "2025-05-15 20:33:39,594 - INFO - Final count for Mass: 12000/12000\n",
      "2025-05-15 20:33:39,691 - INFO - Found 3009 original images for Nodule\n",
      "2025-05-15 20:33:39,697 - INFO - Need to create 8991 more images for Nodule\n",
      "2025-05-15 20:33:39,702 - INFO - Will create 3 augmentations per original image\n",
      "Augmenting Nodule: 100%|██████████████████████████████████████████████████████████████████████████████████████████████▌| 2997/3009 [05:51<00:01,  8.53it/s]\n",
      "2025-05-15 20:39:31,155 - INFO - Created 8991 augmented images for Nodule. Total count: 12000/12000\n",
      "2025-05-15 20:39:31,161 - INFO - Final count for Nodule: 12000/12000\n",
      "2025-05-15 20:39:31,168 - INFO - Found 325 original images for Pneumonia\n",
      "2025-05-15 20:39:31,171 - INFO - Need to create 11675 more images for Pneumonia\n",
      "2025-05-15 20:39:31,175 - INFO - Will create 36 augmentations per original image\n",
      "Augmenting Pneumonia: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 325/325 [05:21<00:00,  1.01it/s]\n",
      "2025-05-15 20:44:52,671 - INFO - Created 11675 augmented images for Pneumonia. Total count: 12000/12000\n",
      "2025-05-15 20:44:52,676 - INFO - Final count for Pneumonia: 12000/12000\n",
      "2025-05-15 20:44:52,746 - INFO - Found 2200 original images for Pneumothorax\n",
      "2025-05-15 20:44:52,752 - INFO - Need to create 9800 more images for Pneumothorax\n",
      "2025-05-15 20:44:52,755 - INFO - Will create 5 augmentations per original image\n",
      "Augmenting Pneumothorax:  89%|███████████████████████████████████████████████████████████████████████████████▎         | 1960/2200 [05:34<00:40,  5.86it/s]\n",
      "2025-05-15 20:50:27,013 - INFO - Created 9800 augmented images for Pneumothorax. Total count: 12000/12000\n",
      "2025-05-15 20:50:27,018 - INFO - Final count for Pneumothorax: 12000/12000\n",
      "2025-05-15 20:50:27,131 - INFO - Found 3331 original images for Consolidation\n",
      "2025-05-15 20:50:27,135 - INFO - Need to create 8669 more images for Consolidation\n",
      "2025-05-15 20:50:27,139 - INFO - Will create 3 augmentations per original image\n",
      "Augmenting Consolidation:  87%|████████████████████████████████████████████████████████████████████████████▎           | 2890/3331 [05:15<00:48,  9.15it/s]\n",
      "2025-05-15 20:55:42,849 - INFO - Created 8669 augmented images for Consolidation. Total count: 12000/12000\n",
      "2025-05-15 20:55:42,857 - INFO - Final count for Consolidation: 12000/12000\n",
      "2025-05-15 20:55:42,915 - INFO - Found 1862 original images for Edema\n",
      "2025-05-15 20:55:42,921 - INFO - Need to create 10138 more images for Edema\n",
      "2025-05-15 20:55:42,926 - INFO - Will create 6 augmentations per original image\n",
      "Augmenting Edema:  91%|███████████████████████████████████████████████████████████████████████████████████████▏        | 1690/1862 [05:25<00:33,  5.19it/s]\n",
      "2025-05-15 21:01:08,858 - INFO - Created 10138 augmented images for Edema. Total count: 12000/12000\n",
      "2025-05-15 21:01:08,864 - INFO - Final count for Edema: 12000/12000\n",
      "2025-05-15 21:01:08,937 - INFO - Found 1734 original images for Emphysema\n",
      "2025-05-15 21:01:08,948 - INFO - Need to create 10266 more images for Emphysema\n",
      "2025-05-15 21:01:08,953 - INFO - Will create 6 augmentations per original image\n",
      "Augmenting Emphysema:  99%|██████████████████████████████████████████████████████████████████████████████████████████▊ | 1711/1734 [05:36<00:04,  5.09it/s]\n",
      "2025-05-15 21:06:45,299 - INFO - Created 10266 augmented images for Emphysema. Total count: 12000/12000\n",
      "2025-05-15 21:06:45,304 - INFO - Final count for Emphysema: 12000/12000\n",
      "2025-05-15 21:06:45,342 - INFO - Found 1215 original images for Fibrosis\n",
      "2025-05-15 21:06:45,348 - INFO - Need to create 10785 more images for Fibrosis\n",
      "2025-05-15 21:06:45,352 - INFO - Will create 9 augmentations per original image\n",
      "Augmenting Fibrosis:  99%|███████████████████████████████████████████████████████████████████████████████████████████▊ | 1199/1215 [05:56<00:04,  3.37it/s]\n",
      "2025-05-15 21:12:41,387 - INFO - Created 10785 augmented images for Fibrosis. Total count: 12000/12000\n",
      "2025-05-15 21:12:41,392 - INFO - Final count for Fibrosis: 12000/12000\n",
      "2025-05-15 21:12:41,430 - INFO - Found 1217 original images for Pleural_Thickening\n",
      "2025-05-15 21:12:41,439 - INFO - Need to create 10783 more images for Pleural_Thickening\n",
      "2025-05-15 21:12:41,447 - INFO - Will create 9 augmentations per original image\n",
      "Augmenting Pleural_Thickening:  99%|█████████████████████████████████████████████████████████████████████████████████▊ | 1199/1217 [05:47<00:05,  3.45it/s]\n",
      "2025-05-15 21:18:28,908 - INFO - Created 10783 augmented images for Pleural_Thickening. Total count: 12000/12000\n",
      "2025-05-15 21:18:28,915 - INFO - Final count for Pleural_Thickening: 12000/12000\n",
      "2025-05-15 21:18:28,944 - INFO - Found 156 original images for Hernia\n",
      "2025-05-15 21:18:28,957 - INFO - Need to create 11844 more images for Hernia\n",
      "2025-05-15 21:18:28,963 - INFO - Will create 76 augmentations per original image\n",
      "Augmenting Hernia: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 156/156 [05:29<00:00,  2.11s/it]\n",
      "2025-05-15 21:23:58,107 - INFO - Created 11844 augmented images for Hernia. Total count: 12000/12000\n",
      "2025-05-15 21:23:58,112 - INFO - Final count for Hernia: 12000/12000\n",
      "2025-05-15 21:23:58,118 - INFO - Augmentation complete. Created 116241 augmented images across all classes.\n",
      "2025-05-15 21:23:58,163 - INFO - Creating train/val/test splits with ratio              Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
      "0       00000001_000.png            Cardiomegaly            0           1   \n",
      "1       00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
      "2       00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
      "3       00000002_000.png              No Finding            0           2   \n",
      "4       00000003_000.png                  Hernia            0           3   \n",
      "...                  ...                     ...          ...         ...   \n",
      "112115  00030801_001.png          Mass|Pneumonia            1       30801   \n",
      "112116  00030802_000.png              No Finding            0       30802   \n",
      "112117  00030803_000.png              No Finding            0       30803   \n",
      "112118  00030804_000.png              No Finding            0       30804   \n",
      "112119  00030805_000.png              No Finding            0       30805   \n",
      "\n",
      "        Patient Age Patient Gender View Position  OriginalImage[Width  \\\n",
      "0                58              M            PA                 2682   \n",
      "1                58              M            PA                 2894   \n",
      "2                58              M            PA                 2500   \n",
      "3                81              M            PA                 2500   \n",
      "4                81              F            PA                 2582   \n",
      "...             ...            ...           ...                  ...   \n",
      "112115           39              M            PA                 2048   \n",
      "112116           29              M            PA                 2048   \n",
      "112117           42              F            PA                 2048   \n",
      "112118           30              F            PA                 2048   \n",
      "112119           27              M            PA                 2048   \n",
      "\n",
      "        Height]  OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
      "0          2749                        0.143  0.143          NaN  \n",
      "1          2729                        0.143  0.143          NaN  \n",
      "2          2048                        0.168  0.168          NaN  \n",
      "3          2048                        0.171  0.171          NaN  \n",
      "4          2991                        0.143  0.143          NaN  \n",
      "...         ...                          ...    ...          ...  \n",
      "112115     2500                        0.168  0.168          NaN  \n",
      "112116     2500                        0.168  0.168          NaN  \n",
      "112117     2500                        0.168  0.168          NaN  \n",
      "112118     2500                        0.168  0.168          NaN  \n",
      "112119     2500                        0.171  0.171          NaN  \n",
      "\n",
      "[112120 rows x 12 columns]/['images_001', 'images_002', 'images_003', 'images_004', 'images_005', 'images_006', 'images_007', 'images_008', 'images_009', 'images_010', 'images_011', 'images_012']/['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']...\n",
      "2025-05-15 21:23:58,170 - WARNING - No augmented directory for C\n",
      "2025-05-15 21:23:58,176 - WARNING - No augmented directory for :\n",
      "2025-05-15 21:23:58,183 - INFO - Creating split for \\ with 25 images\n",
      "2025-05-15 21:23:58,422 - ERROR - Error creating splits: int() argument must be a string, a bytes-like object or a real number, not 'DataFrame'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_38992\\3266818677.py\", line 231, in create_train_val_test_split\n",
      "    n_train = int(n_total * train_ratio)\n",
      "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'DataFrame'\n",
      "2025-05-15 21:23:58,448 - INFO - \n",
      "Preprocessing pipeline complete!\n",
      "2025-05-15 21:23:58,454 - INFO - Final dataset:\n",
      "2025-05-15 21:23:58,460 - INFO - - Train: 0 images\n",
      "2025-05-15 21:23:58,467 - INFO - - Validation: 0 images\n",
      "2025-05-15 21:23:58,472 - INFO - - Test: 0 images\n",
      "2025-05-15 21:23:58,478 - INFO - Total: 0 images\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(\"preprocessing.log\")\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_directories(base_dir, labels):\n",
    "    \"\"\"Create all necessary directories for the project.\"\"\"\n",
    "    logger.info(\"Creating necessary directories...\")\n",
    "    for folder in [\"data/augmented\", \"data/train\", \"data/val\", \"data/test\", \"uploads\", \"models\", \"reports\", \"logs\"]:\n",
    "        dir_path = os.path.join(base_dir, folder.replace(\"/\", os.sep))\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Create label-specific directories in each data split folder\n",
    "    for split in [\"augmented\", \"train\", \"val\", \"test\"]:\n",
    "        for label in labels:\n",
    "            label_dir = os.path.join(base_dir, \"data\", split, label)\n",
    "            os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "def perform_augmentation(base_dir, labels, target_count=12000):\n",
    "    \"\"\"Perform image augmentation to ensure each class has exactly target_count images.\"\"\"\n",
    "    logger.info(f\"Starting image augmentation with target of {target_count} images per class...\")\n",
    "    \n",
    "    # Define augmentation pipeline\n",
    "    transform = A.Compose([\n",
    "        A.Resize(256, 256),\n",
    "        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=1.0),\n",
    "        A.Rotate(limit=15, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.3),\n",
    "        A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2)\n",
    "    ])\n",
    "    \n",
    "    augmented_count = 0\n",
    "    augmented_per_class = {}\n",
    "    \n",
    "    for label in labels:\n",
    "        label_dir = os.path.join(base_dir, \"data\", \"augmented\", label)\n",
    "        if not os.path.exists(label_dir):\n",
    "            logger.warning(f\"Directory not found for {label}, creating it\")\n",
    "            os.makedirs(label_dir, exist_ok=True)\n",
    "            continue\n",
    "        \n",
    "        # Only consider original images (not already augmented ones)\n",
    "        images = [f for f in os.listdir(label_dir) if not \"_aug\" in f]\n",
    "        \n",
    "        if not images:\n",
    "            logger.warning(f\"No images found for {label}\")\n",
    "            continue\n",
    "        \n",
    "        original_count = len(images)\n",
    "        logger.info(f\"Found {original_count} original images for {label}\")\n",
    "        \n",
    "        # Calculate how many augmentations needed per image to reach target\n",
    "        if original_count >= target_count:\n",
    "            logger.info(f\"Class {label} already has {original_count} images, no augmentation needed\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate required augmentations\n",
    "        remaining_images = target_count - original_count\n",
    "        aug_per_image = math.ceil(remaining_images / original_count)\n",
    "        \n",
    "        logger.info(f\"Need to create {remaining_images} more images for {label}\")\n",
    "        logger.info(f\"Will create {aug_per_image} augmentations per original image\")\n",
    "        \n",
    "        class_aug_count = 0\n",
    "        \n",
    "        # Use tqdm for progress tracking\n",
    "        for img_name in tqdm(images, desc=f\"Augmenting {label}\"):\n",
    "            img_path = os.path.join(label_dir, img_name)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    logger.warning(f\"Could not read {img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Convert to grayscale if the image is in color\n",
    "                if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                    # Convert back to 3-channel for compatibility with albumentations\n",
    "                    img = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2BGR)\n",
    "                elif len(img.shape) == 2:\n",
    "                    # If already grayscale, convert to 3-channel for compatibility\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "                \n",
    "                base_name = os.path.splitext(img_name)[0]\n",
    "                ext = os.path.splitext(img_name)[1]\n",
    "                \n",
    "                # Stop augmenting if we've reached our target\n",
    "                if original_count + class_aug_count >= target_count:\n",
    "                    break\n",
    "                \n",
    "                # Create the calculated number of augmentations per image\n",
    "                for i in range(aug_per_image):\n",
    "                    # Break if we've reached our target\n",
    "                    if original_count + class_aug_count >= target_count:\n",
    "                        break\n",
    "                        \n",
    "                    try:\n",
    "                        # Apply augmentation\n",
    "                        augmented = transform(image=img)[\"image\"]\n",
    "                        # Save the augmented image\n",
    "                        output_path = os.path.join(label_dir, f\"{base_name}_aug{i}{ext}\")\n",
    "                        cv2.imwrite(output_path, augmented)\n",
    "                        class_aug_count += 1\n",
    "                        augmented_count += 1\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error augmenting {img_path} (iteration {i}): {e}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {img_path}: {e}\")\n",
    "        \n",
    "        final_count = original_count + class_aug_count\n",
    "        augmented_per_class[label] = class_aug_count\n",
    "        logger.info(f\"Created {class_aug_count} augmented images for {label}. Total count: {final_count}/{target_count}\")\n",
    "        \n",
    "        # In case we need additional augmentations to exactly reach the target\n",
    "        if final_count < target_count:\n",
    "            logger.warning(f\"Still need {target_count - final_count} more images for {label}\")\n",
    "            # Augment from already augmented images if needed\n",
    "            all_images = os.listdir(label_dir)\n",
    "            additional_needed = target_count - final_count\n",
    "            \n",
    "            if all_images:\n",
    "                additional_per_image = math.ceil(additional_needed / len(all_images))\n",
    "                additional_count = 0\n",
    "                \n",
    "                for img_name in tqdm(all_images, desc=f\"Additional augmentation for {label}\"):\n",
    "                    if final_count + additional_count >= target_count:\n",
    "                        break\n",
    "                        \n",
    "                    img_path = os.path.join(label_dir, img_name)\n",
    "                    try:\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is None:\n",
    "                            continue\n",
    "                            \n",
    "                        base_name = os.path.splitext(img_name)[0]\n",
    "                        ext = os.path.splitext(img_name)[1]\n",
    "                        \n",
    "                        for i in range(additional_per_image):\n",
    "                            if final_count + additional_count >= target_count:\n",
    "                                break\n",
    "                                \n",
    "                            # Use a stronger augmentation for these additional images\n",
    "                            strong_transform = A.Compose([\n",
    "                                A.Resize(256, 256),\n",
    "                                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=1.0),\n",
    "                                A.Rotate(limit=30, p=0.8),\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.VerticalFlip(p=0.3),\n",
    "                                A.RandomBrightnessContrast(p=0.5),\n",
    "                                A.GaussNoise(p=0.3),\n",
    "                                A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.5)\n",
    "                            ])\n",
    "                            \n",
    "                            augmented = strong_transform(image=img)[\"image\"]\n",
    "                            output_path = os.path.join(label_dir, f\"{base_name}_extra{i}{ext}\")\n",
    "                            cv2.imwrite(output_path, augmented)\n",
    "                            additional_count += 1\n",
    "                            augmented_count += 1\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error in additional augmentation for {img_path}: {e}\")\n",
    "                \n",
    "                logger.info(f\"Created {additional_count} additional augmented images for {label}\")\n",
    "                final_count += additional_count\n",
    "                augmented_per_class[label] += additional_count\n",
    "        \n",
    "        logger.info(f\"Final count for {label}: {final_count}/{target_count}\")\n",
    "    \n",
    "    logger.info(f\"Augmentation complete. Created {augmented_count} augmented images across all classes.\")\n",
    "    return augmented_per_class\n",
    "\n",
    "\n",
    "def find_image(image_name, archive_dir, image_folders):\n",
    "    \"\"\"Find an image in all available image folders.\"\"\"\n",
    "    for folder in image_folders:\n",
    "        img_path = os.path.join(archive_dir, folder, image_name)\n",
    "        if os.path.exists(img_path):\n",
    "            return img_path\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    # Setup directories\n",
    "    base_dir = r\"C:\\projects_ml\\Radi_Assist\"\n",
    "    archive_dir = os.path.join(base_dir, \"data\", \"raw\", \"archive\")\n",
    "    \n",
    "    labels = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\",\n",
    "              \"Pneumonia\", \"Pneumothorax\", \"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\",\n",
    "              \"Pleural_Thickening\", \"Hernia\"]\n",
    "    \n",
    "    # Target count for each class\n",
    "    target_count = 12000\n",
    "    \n",
    "    # Create all necessary directories\n",
    "    create_directories(base_dir, labels)\n",
    "    \n",
    "    # Load CSV file\n",
    "    csv_path = os.path.join(archive_dir, \"Data_Entry_2017.csv\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        logger.error(f\"Cannot find CSV file at {csv_path}\")\n",
    "        # Try to find alternative CSV\n",
    "        csv_files = [f for f in os.listdir(archive_dir) if f.endswith('.csv')]\n",
    "        if csv_files:\n",
    "            csv_path = os.path.join(archive_dir, csv_files[0])\n",
    "            logger.info(f\"Using alternative CSV file: {csv_path}\")\n",
    "        else:\n",
    "            logger.error(f\"No CSV files found in {archive_dir}\")\n",
    "            return\n",
    "    \n",
    "    logger.info(f\"Loading data from {csv_path}...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    logger.info(f\"CSV loaded with {len(df)} records and columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    required_cols = [\"Image Index\", \"Finding Labels\"]\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            similar_cols = [c for c in df.columns if c.lower().replace(\" \", \"_\") == col.lower().replace(\" \", \"_\")]\n",
    "            if similar_cols:\n",
    "                logger.info(f\"Renaming column '{similar_cols[0]}' to '{col}'\")\n",
    "                df = df.rename(columns={similar_cols[0]: col})\n",
    "            else:\n",
    "                logger.error(f\"Required column '{col}' not found in CSV\")\n",
    "                return\n",
    "    \n",
    "    # Find image folders\n",
    "    image_folders = []\n",
    "    for i in range(1, 13):\n",
    "        folder_name = f\"images_{str(i).zfill(3)}\"\n",
    "        folder_path = os.path.join(archive_dir, folder_name)\n",
    "        if os.path.exists(folder_path):\n",
    "            # Check if folder contains any images\n",
    "            files = os.listdir(folder_path)\n",
    "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            if image_files:\n",
    "                image_folders.append(folder_name)\n",
    "                logger.info(f\"Found image folder {folder_name} with {len(image_files)} images\")\n",
    "            else:\n",
    "                logger.warning(f\"Folder {folder_name} exists but contains no image files\")\n",
    "        else:\n",
    "            logger.warning(f\"Image folder {folder_name} not found\")\n",
    "    \n",
    "    # Verify images in augmented folders\n",
    "    image_counts = verify_images(base_dir, labels)\n",
    "    logger.info(\"Current images per class:\")\n",
    "    for label, count in image_counts.items():\n",
    "        logger.info(f\"- {label}: {count}\")\n",
    "    \n",
    "    # Only perform augmentation if needed\n",
    "    if sum(image_counts.values()) == 0:\n",
    "        logger.warning(\"No images found in augmented folders. Check if images were copied correctly.\")\n",
    "        # If no images were copied to the augmented folders, we need to do that first\n",
    "        logger.info(\"Attempting to copy original images to augmented folders...\")\n",
    "        \n",
    "        copied_images = 0\n",
    "        label_counts = {label: 0 for label in labels}\n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Copying original images\"):\n",
    "            try:\n",
    "                img_name = row[\"Image Index\"]\n",
    "                findings = row[\"Finding Labels\"].split(\"|\")\n",
    "                \n",
    "                if \"No Finding\" in findings:\n",
    "                    continue\n",
    "                    \n",
    "                label = findings[0]\n",
    "                if label not in labels:\n",
    "                    continue\n",
    "                    \n",
    "                # Find the image\n",
    "                src_path = find_image(img_name, archive_dir, image_folders)\n",
    "                if src_path:\n",
    "                    dest_path = os.path.join(base_dir, \"data\", \"augmented\", label, img_name)\n",
    "                    shutil.copy(src_path, dest_path)\n",
    "                    copied_images += 1\n",
    "                    label_counts[label] += 1\n",
    "                    \n",
    "                    if copied_images % 500 == 0:\n",
    "                        logger.info(f\"Copied {copied_images} images so far...\")\n",
    "                else:\n",
    "                    if idx % 1000 == 0:\n",
    "                        logger.warning(f\"Could not find image for row {idx}: {img_name}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing row {idx}: {e}\")\n",
    "        \n",
    "        logger.info(f\"Copied {copied_images} original images to augmented folders\")\n",
    "        for label, count in label_counts.items():\n",
    "            logger.info(f\"- {label}: {count}\")\n",
    "    \n",
    "    # Perform image augmentation with target count\n",
    "    augmented_counts = perform_augmentation(base_dir, labels, target_count=target_count)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274282e1-ab81-4eb2-bd00-14902fa611eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 05:01:02,864 - INFO - Creating necessary directories...\n",
      "2025-05-16 05:01:02,956 - INFO - Current images per class in augmented folders:\n",
      "2025-05-16 05:01:02,957 - INFO - - Atelectasis: 2500\n",
      "2025-05-16 05:01:02,958 - INFO - - Cardiomegaly: 2500\n",
      "2025-05-16 05:01:02,959 - INFO - - Effusion: 2500\n",
      "2025-05-16 05:01:02,960 - INFO - - Infiltration: 2500\n",
      "2025-05-16 05:01:02,961 - INFO - - Mass: 2500\n",
      "2025-05-16 05:01:02,962 - INFO - - Nodule: 2500\n",
      "2025-05-16 05:01:02,963 - INFO - - Pneumonia: 2500\n",
      "2025-05-16 05:01:02,964 - INFO - - Pneumothorax: 2500\n",
      "2025-05-16 05:01:02,965 - INFO - - Consolidation: 2500\n",
      "2025-05-16 05:01:02,966 - INFO - - Edema: 2500\n",
      "2025-05-16 05:01:02,967 - INFO - - Emphysema: 2500\n",
      "2025-05-16 05:01:02,968 - INFO - - Fibrosis: 2500\n",
      "2025-05-16 05:01:02,969 - INFO - - Pleural_Thickening: 2500\n",
      "2025-05-16 05:01:02,970 - INFO - - Hernia: 2500\n",
      "2025-05-16 05:01:02,971 - INFO - Creating train/val/test splits with ratio 0.7/0.1/0.2...\n",
      "2025-05-16 05:01:02,980 - INFO - Creating split for Atelectasis with 2500 images\n",
      "Copying Atelectasis train images: 100%|███████████████████████████████████████████| 1750/1750 [00:06<00:00, 278.70it/s]\n",
      "Copying Atelectasis validation images: 100%|████████████████████████████████████████| 250/250 [00:00<00:00, 294.65it/s]\n",
      "Copying Atelectasis test images: 100%|██████████████████████████████████████████████| 500/500 [00:02<00:00, 248.37it/s]\n",
      "2025-05-16 05:01:12,135 - INFO - Split for Atelectasis: Train=1750, Val=250, Test=500\n",
      "2025-05-16 05:01:12,144 - INFO - Creating split for Cardiomegaly with 2500 images\n",
      "Copying Cardiomegaly train images: 100%|██████████████████████████████████████████| 1705/1705 [00:05<00:00, 294.98it/s]\n",
      "Copying Cardiomegaly validation images: 100%|███████████████████████████████████████| 280/280 [00:00<00:00, 321.78it/s]\n",
      "Copying Cardiomegaly test images: 100%|█████████████████████████████████████████████| 515/515 [00:01<00:00, 317.66it/s]\n",
      "2025-05-16 05:01:20,436 - INFO - Split for Cardiomegaly: Train=1705, Val=280, Test=515\n",
      "2025-05-16 05:01:20,448 - INFO - Creating split for Effusion with 2500 images\n",
      "Copying Effusion train images: 100%|██████████████████████████████████████████████| 1750/1750 [00:06<00:00, 271.80it/s]\n",
      "Copying Effusion validation images: 100%|███████████████████████████████████████████| 250/250 [00:00<00:00, 302.87it/s]\n",
      "Copying Effusion test images: 100%|█████████████████████████████████████████████████| 500/500 [00:01<00:00, 259.44it/s]\n",
      "2025-05-16 05:01:29,654 - INFO - Split for Effusion: Train=1750, Val=250, Test=500\n",
      "2025-05-16 05:01:29,669 - INFO - Creating split for Infiltration with 2500 images\n",
      "Copying Infiltration train images: 100%|██████████████████████████████████████████| 1750/1750 [00:06<00:00, 268.73it/s]\n",
      "Copying Infiltration validation images: 100%|███████████████████████████████████████| 250/250 [00:00<00:00, 298.57it/s]\n",
      "Copying Infiltration test images: 100%|█████████████████████████████████████████████| 500/500 [00:01<00:00, 292.75it/s]\n",
      "2025-05-16 05:01:38,738 - INFO - Split for Infiltration: Train=1750, Val=250, Test=500\n",
      "2025-05-16 05:01:38,747 - INFO - Creating split for Mass with 2500 images\n",
      "Copying Mass train images: 100%|██████████████████████████████████████████████████| 1733/1733 [00:10<00:00, 161.23it/s]\n",
      "Copying Mass validation images: 100%|███████████████████████████████████████████████| 260/260 [00:01<00:00, 163.63it/s]\n",
      "Copying Mass test images: 100%|█████████████████████████████████████████████████████| 507/507 [00:03<00:00, 165.94it/s]\n",
      "2025-05-16 05:01:54,151 - INFO - Split for Mass: Train=1733, Val=260, Test=507\n",
      "2025-05-16 05:01:54,159 - INFO - Creating split for Nodule with 2500 images\n",
      "Copying Nodule train images: 100%|████████████████████████████████████████████████| 1764/1764 [00:10<00:00, 171.11it/s]\n",
      "Copying Nodule validation images: 100%|█████████████████████████████████████████████| 243/243 [00:01<00:00, 184.87it/s]\n",
      "Copying Nodule test images: 100%|███████████████████████████████████████████████████| 493/493 [00:02<00:00, 164.90it/s]\n",
      "2025-05-16 05:02:08,786 - INFO - Split for Nodule: Train=1764, Val=243, Test=493\n",
      "2025-05-16 05:02:08,793 - INFO - Creating split for Pneumonia with 2500 images\n",
      "Copying Pneumonia train images: 100%|█████████████████████████████████████████████| 1670/1670 [00:06<00:00, 267.85it/s]\n",
      "Copying Pneumonia validation images: 100%|██████████████████████████████████████████| 277/277 [00:01<00:00, 237.00it/s]\n",
      "Copying Pneumonia test images: 100%|████████████████████████████████████████████████| 553/553 [00:02<00:00, 236.15it/s]\n",
      "2025-05-16 05:02:18,550 - INFO - Split for Pneumonia: Train=1670, Val=277, Test=553\n",
      "2025-05-16 05:02:18,558 - INFO - Creating split for Pneumothorax with 2500 images\n",
      "Copying Pneumothorax train images: 100%|██████████████████████████████████████████| 1757/1757 [00:08<00:00, 196.04it/s]\n",
      "Copying Pneumothorax validation images: 100%|███████████████████████████████████████| 255/255 [00:01<00:00, 135.77it/s]\n",
      "Copying Pneumothorax test images: 100%|█████████████████████████████████████████████| 488/488 [00:02<00:00, 236.28it/s]\n",
      "2025-05-16 05:02:31,475 - INFO - Split for Pneumothorax: Train=1757, Val=255, Test=488\n",
      "2025-05-16 05:02:31,483 - INFO - Creating split for Consolidation with 2500 images\n",
      "Copying Consolidation train images: 100%|█████████████████████████████████████████| 1755/1755 [00:10<00:00, 172.47it/s]\n",
      "Copying Consolidation validation images: 100%|██████████████████████████████████████| 272/272 [00:01<00:00, 188.40it/s]\n",
      "Copying Consolidation test images: 100%|████████████████████████████████████████████| 473/473 [00:02<00:00, 191.76it/s]\n",
      "2025-05-16 05:02:45,582 - INFO - Split for Consolidation: Train=1755, Val=272, Test=473\n",
      "2025-05-16 05:02:45,590 - INFO - Creating split for Edema with 2500 images\n",
      "Copying Edema train images: 100%|█████████████████████████████████████████████████| 1730/1730 [00:10<00:00, 172.55it/s]\n",
      "Copying Edema validation images: 100%|██████████████████████████████████████████████| 266/266 [00:01<00:00, 167.77it/s]\n",
      "Copying Edema test images: 100%|████████████████████████████████████████████████████| 504/504 [00:02<00:00, 174.71it/s]\n",
      "2025-05-16 05:03:00,099 - INFO - Split for Edema: Train=1730, Val=266, Test=504\n",
      "2025-05-16 05:03:00,109 - INFO - Creating split for Emphysema with 2500 images\n",
      "Copying Emphysema train images: 100%|█████████████████████████████████████████████| 1715/1715 [00:10<00:00, 165.48it/s]\n",
      "Copying Emphysema validation images: 100%|██████████████████████████████████████████| 246/246 [00:01<00:00, 151.48it/s]\n",
      "Copying Emphysema test images: 100%|████████████████████████████████████████████████| 539/539 [00:03<00:00, 173.77it/s]\n",
      "2025-05-16 05:03:15,213 - INFO - Split for Emphysema: Train=1715, Val=246, Test=539\n",
      "2025-05-16 05:03:15,380 - INFO - Creating split for Fibrosis with 2500 images\n",
      "Copying Fibrosis train images: 100%|██████████████████████████████████████████████| 1736/1736 [00:10<00:00, 162.59it/s]\n",
      "Copying Fibrosis validation images: 100%|███████████████████████████████████████████| 241/241 [00:01<00:00, 170.45it/s]\n",
      "Copying Fibrosis test images: 100%|█████████████████████████████████████████████████| 523/523 [00:02<00:00, 194.90it/s]\n",
      "2025-05-16 05:03:30,172 - INFO - Split for Fibrosis: Train=1736, Val=241, Test=523\n",
      "2025-05-16 05:03:30,184 - INFO - Creating split for Pleural_Thickening with 2500 images\n",
      "Copying Pleural_Thickening train images: 100%|████████████████████████████████████| 1724/1724 [00:09<00:00, 178.23it/s]\n",
      "Copying Pleural_Thickening validation images: 100%|█████████████████████████████████| 268/268 [00:01<00:00, 191.53it/s]\n",
      "Copying Pleural_Thickening test images: 100%|███████████████████████████████████████| 508/508 [00:03<00:00, 127.64it/s]\n",
      "2025-05-16 05:03:45,252 - INFO - Split for Pleural_Thickening: Train=1724, Val=268, Test=508\n",
      "2025-05-16 05:03:45,631 - INFO - Creating split for Hernia with 2500 images\n",
      "Copying Hernia train images: 100%|████████████████████████████████████████████████| 1696/1696 [00:09<00:00, 176.44it/s]\n",
      "Copying Hernia validation images: 100%|█████████████████████████████████████████████| 231/231 [00:00<00:00, 257.89it/s]\n",
      "Copying Hernia test images: 100%|███████████████████████████████████████████████████| 573/573 [00:03<00:00, 175.70it/s]\n",
      "2025-05-16 05:03:59,418 - INFO - Split for Hernia: Train=1696, Val=231, Test=573\n",
      "2025-05-16 05:03:59,419 - INFO - Total split: Train=24235, Val=3589, Test=7176\n",
      "2025-05-16 05:03:59,420 - WARNING - create_label_distribution_plot function not found, skipping plot creation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'count_images_in_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 183\u001b[39m\n\u001b[32m    180\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_images\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mval_images\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mtest_images\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    166\u001b[39m train_count, val_count, test_count = create_train_val_test_split(\n\u001b[32m    167\u001b[39m     base_dir, labels, train_ratio=\u001b[32m0.7\u001b[39m, val_ratio=\u001b[32m0.1\u001b[39m, test_ratio=\u001b[32m0.2\u001b[39m\n\u001b[32m    168\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# Verify images in each split\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m train_images = \u001b[43mcount_images_in_split\u001b[49m(base_dir, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, labels)\n\u001b[32m    172\u001b[39m val_images = count_images_in_split(base_dir, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m, labels)\n\u001b[32m    173\u001b[39m test_images = count_images_in_split(base_dir, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, labels)\n",
      "\u001b[31mNameError\u001b[39m: name 'count_images_in_split' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(\"preprocessing.log\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def create_directories(base_dir, labels):\n",
    "    \"\"\"Create all necessary directories for the project.\"\"\"\n",
    "    logger.info(\"Creating necessary directories...\")\n",
    "    for folder in [\"data/augmented\", \"data/train\", \"data/val\", \"data/test\", \"uploads\", \"models\", \"reports\", \"logs\"]:\n",
    "        dir_path = os.path.join(base_dir, folder.replace(\"/\", os.sep))\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Create label-specific directories in each data split folder\n",
    "    for split in [\"augmented\", \"train\", \"val\", \"test\"]:\n",
    "        for label in labels:\n",
    "            label_dir = os.path.join(base_dir, \"data\", split, label)\n",
    "            os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "def create_train_val_test_split(base_dir, labels, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2):\n",
    "    \"\"\"Create and save train/validation/test splits directly from augmented data.\"\"\"\n",
    "    logger.info(f\"Creating train/val/test splits with ratio {train_ratio}/{val_ratio}/{test_ratio}...\")\n",
    "    \n",
    "    try:\n",
    "        total_train = 0\n",
    "        total_val = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        for label in labels:\n",
    "            # Get all images from augmented folder for this label\n",
    "            aug_dir = os.path.join(base_dir, \"data\", \"augmented\", label)\n",
    "            if not os.path.exists(aug_dir):\n",
    "                logger.warning(f\"No augmented directory for {label}\")\n",
    "                continue\n",
    "            \n",
    "            # Create destination directories if they don't exist\n",
    "            train_dir = os.path.join(base_dir, \"data\", \"train\", label)\n",
    "            val_dir = os.path.join(base_dir, \"data\", \"val\", label)\n",
    "            test_dir = os.path.join(base_dir, \"data\", \"test\", label)\n",
    "            \n",
    "            os.makedirs(train_dir, exist_ok=True)\n",
    "            os.makedirs(val_dir, exist_ok=True)\n",
    "            os.makedirs(test_dir, exist_ok=True)\n",
    "            \n",
    "            # Get all images (both original and augmented)\n",
    "            all_images = os.listdir(aug_dir)\n",
    "            if not all_images:\n",
    "                logger.warning(f\"No images found for {label} in augmented folder\")\n",
    "                continue\n",
    "            \n",
    "            logger.info(f\"Creating split for {label} with {len(all_images)} images\")\n",
    "            \n",
    "            # Group by base image name (to keep augmented versions together)\n",
    "            image_groups = {}\n",
    "            for img in all_images:\n",
    "                base_name = img.split('_aug')[0] if '_aug' in img else img\n",
    "                base_name = base_name.split('_extra')[0] if '_extra' in base_name else base_name\n",
    "                if base_name not in image_groups:\n",
    "                    image_groups[base_name] = []\n",
    "                image_groups[base_name].append(img)\n",
    "            \n",
    "            # Split by base image\n",
    "            base_images = list(image_groups.keys())\n",
    "            \n",
    "            # Calculate split sizes\n",
    "            n_total = len(base_images)\n",
    "            n_train = int(n_total * train_ratio)\n",
    "            n_val = int(n_total * val_ratio)\n",
    "            # n_test will be the remainder\n",
    "            \n",
    "            # Shuffle and split\n",
    "            np.random.shuffle(base_images)\n",
    "            train_bases = base_images[:n_train]\n",
    "            val_bases = base_images[n_train:n_train+n_val]\n",
    "            test_bases = base_images[n_train+n_val:]\n",
    "            \n",
    "            # Get all images for each split\n",
    "            train_images = [img for base in train_bases for img in image_groups[base]]\n",
    "            val_images = [img for base in val_bases for img in image_groups[base]]\n",
    "            test_images = [img for base in test_bases for img in image_groups[base]]\n",
    "            \n",
    "            # Copy images to respective directories\n",
    "            for img in tqdm(train_images, desc=f\"Copying {label} train images\"):\n",
    "                src_path = os.path.join(aug_dir, img)\n",
    "                dst_path = os.path.join(base_dir, \"data\", \"train\", label, img)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "            \n",
    "            for img in tqdm(val_images, desc=f\"Copying {label} validation images\"):\n",
    "                src_path = os.path.join(aug_dir, img)\n",
    "                dst_path = os.path.join(base_dir, \"data\", \"val\", label, img)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "            \n",
    "            for img in tqdm(test_images, desc=f\"Copying {label} test images\"):\n",
    "                src_path = os.path.join(aug_dir, img)\n",
    "                dst_path = os.path.join(base_dir, \"data\", \"test\", label, img)\n",
    "                shutil.copy(src_path, dst_path)\n",
    "            \n",
    "            # Update counts\n",
    "            total_train += len(train_images)\n",
    "            total_val += len(val_images)\n",
    "            total_test += len(test_images)\n",
    "            \n",
    "            logger.info(f\"Split for {label}: Train={len(train_images)}, Val={len(val_images)}, Test={len(test_images)}\")\n",
    "        \n",
    "        logger.info(f\"Total split: Train={total_train}, Val={total_val}, Test={total_test}\")\n",
    "        \n",
    "        # Create label distribution plots if the function exists\n",
    "        try:\n",
    "            create_label_distribution_plot(base_dir, labels)\n",
    "        except NameError:\n",
    "            logger.warning(\"create_label_distribution_plot function not found, skipping plot creation\")\n",
    "        \n",
    "        return total_train, total_val, total_test\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating splits: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return 0, 0, 0\n",
    "\n",
    "def main():\n",
    "    # Setup directories\n",
    "    base_dir = r\"C:\\projects_ml\\Radi_Assist\"\n",
    "    archive_dir = os.path.join(base_dir, \"data\", \"raw\", \"archive\")\n",
    "    \n",
    "    labels = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\",\n",
    "              \"Pneumonia\", \"Pneumothorax\", \"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\",\n",
    "              \"Pleural_Thickening\", \"Hernia\"]\n",
    "    \n",
    "    # Create all necessary directories\n",
    "    create_directories(base_dir, labels)\n",
    "    \n",
    "    # Verify images in augmented folders\n",
    "    image_counts = {}\n",
    "    for label in labels:\n",
    "        aug_dir = os.path.join(base_dir, \"data\", \"augmented\", label)\n",
    "        if os.path.exists(aug_dir):\n",
    "            image_counts[label] = len(os.listdir(aug_dir))\n",
    "        else:\n",
    "            image_counts[label] = 0\n",
    "    \n",
    "    logger.info(\"Current images per class in augmented folders:\")\n",
    "    for label, count in image_counts.items():\n",
    "        logger.info(f\"- {label}: {count}\")\n",
    "    \n",
    "    # Create train/val/test splits - this is the crucial part that was causing issues\n",
    "    train_count, val_count, test_count = create_train_val_test_split(\n",
    "        base_dir, labels, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2\n",
    "    )\n",
    "    \n",
    "    # Verify images in each split\n",
    "    train_images = count_images_in_split(base_dir, \"train\", labels)\n",
    "    val_images = count_images_in_split(base_dir, \"val\", labels)\n",
    "    test_images = count_images_in_split(base_dir, \"test\", labels)\n",
    "    \n",
    "    logger.info(\"\\nSplitting process complete!\")\n",
    "    logger.info(f\"Final dataset:\")\n",
    "    logger.info(f\"- Train: {train_images} images\")\n",
    "    logger.info(f\"- Validation: {val_images} images\")\n",
    "    logger.info(f\"- Test: {test_images} images\")\n",
    "    logger.info(f\"Total: {train_images + val_images + test_images} images\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55621c11-ed15-49ab-a50f-cc2d27ab4999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (radi_assist_env)",
   "language": "python",
   "name": "venv_training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
