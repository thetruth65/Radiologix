{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd68a8-862a-4721-8318-9e1114ced653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Updated Imports - Add these at the top of your script\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "# New imports for EfficientNet-B1\n",
    "from torchvision.models import efficientnet_b1, EfficientNet_B1_Weights\n",
    "# For Windows memory management\n",
    "import gc\n",
    "\n",
    "labels = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\", \"Mass\", \"Nodule\",\n",
    "          \"Pneumonia\", \"Pneumothorax\", \"Consolidation\", \"Edema\", \"Emphysema\", \"Fibrosis\",\n",
    "          \"Pleural_Thickening\", \"Hernia\"]\n",
    "\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    BASE_DIR = \"C:/projects_ml/Radi_Assist\"\n",
    "    DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "    MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "    MODEL_NAME = 'efficientnet_b1'\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Reduce batch size to avoid GPU memory issues\n",
    "    BATCH_SIZE = 8  # Reduced from 16 to 8\n",
    "    NUM_EPOCHS = 7\n",
    "    LEARNING_RATE = 0.0001\n",
    "    IMG_SIZE = 224\n",
    "    SEED = 42\n",
    "    \n",
    "    @classmethod\n",
    "    def create_directories(cls):\n",
    "        os.makedirs(cls.MODEL_DIR, exist_ok=True)\n",
    "        os.makedirs(cls.RESULTS_DIR, exist_ok=True)\n",
    "        os.makedirs(os.path.join(cls.RESULTS_DIR, \"plots\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(cls.RESULTS_DIR, \"predictions\"), exist_ok=True)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Custom dataset for chest X-ray images\n",
    "class ChestXRayDataset(Dataset):\n",
    "    def __init__(self, image_paths, targets=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        \n",
    "        try:\n",
    "            # Optimize image loading\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image at {img_path}\")\n",
    "                img = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE), dtype=np.uint8)\n",
    "            \n",
    "            # Simplify conversion - create 3-channel image\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "                \n",
    "            if self.targets is not None:\n",
    "                return img, self.targets[idx]\n",
    "            else:\n",
    "                return img\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {str(e)}\")\n",
    "            # Return zero tensor with correct dimensions\n",
    "            if self.transform:\n",
    "                default_img = torch.zeros((3, Config.IMG_SIZE, Config.IMG_SIZE))\n",
    "            else:\n",
    "                default_img = np.zeros((Config.IMG_SIZE, Config.IMG_SIZE, 3), dtype=np.uint8)\n",
    "            \n",
    "            if self.targets is not None:\n",
    "                return default_img, self.targets[idx]\n",
    "            else:\n",
    "                return default_img\n",
    "\n",
    "# Data preparation and loading\n",
    "def prepare_data():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PREPARING DATASET\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Define transformations\n",
    "    train_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomRotation(10),\n",
    "        T.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_test_transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Collect images and labels from train, val, test folders\n",
    "    data_splits = {\n",
    "        'train': {'images': [], 'labels': []},\n",
    "        'val': {'images': [], 'labels': []},\n",
    "        'test': {'images': [], 'labels': []}\n",
    "    }\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_dir = os.path.join(Config.DATA_DIR, split)\n",
    "        if not os.path.exists(split_dir):\n",
    "            raise ValueError(f\"Directory {split_dir} does not exist\")\n",
    "            \n",
    "        for i, class_name in enumerate(labels):\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                image_files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) \n",
    "                             if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                \n",
    "                if image_files:\n",
    "                    print(f\"Found {len(image_files)} images for class '{class_name}' in {split} set\")\n",
    "                    data_splits[split]['images'].extend(image_files)\n",
    "                    label = np.zeros(len(labels))\n",
    "                    label[i] = 1\n",
    "                    data_splits[split]['labels'].extend([label] * len(image_files))\n",
    "    \n",
    "    # Convert labels to numpy arrays\n",
    "    for split in data_splits:\n",
    "        data_splits[split]['labels'] = np.array(data_splits[split]['labels'])\n",
    "    \n",
    "    # Check if we have data\n",
    "    for split in data_splits:\n",
    "        if len(data_splits[split]['images']) == 0:\n",
    "            raise ValueError(f\"No images found in {split} directory\")\n",
    "    \n",
    "    print(f\"\\nDataset split sizes:\")\n",
    "    print(f\"Train: {len(data_splits['train']['images'])} images\")\n",
    "    print(f\"Validation: {len(data_splits['val']['images'])} images\")\n",
    "    print(f\"Test: {len(data_splits['test']['images'])} images\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = ChestXRayDataset(\n",
    "        data_splits['train']['images'], \n",
    "        data_splits['train']['labels'], \n",
    "        transform=train_transform\n",
    "    )\n",
    "    val_dataset = ChestXRayDataset(\n",
    "        data_splits['val']['images'], \n",
    "        data_splits['val']['labels'], \n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    test_dataset = ChestXRayDataset(\n",
    "        data_splits['test']['images'], \n",
    "        data_splits['test']['labels'], \n",
    "        transform=val_test_transform\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    num_workers = 2  # Reduce from 4 to 2\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=Config.BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=Config.BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=Config.BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers, \n",
    "        pin_memory=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    # Visualize data distribution\n",
    "    try:\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        class_counts = np.sum(data_splits['train']['labels'], axis=0)\n",
    "        plt.bar(labels, class_counts)\n",
    "        plt.title('Class Distribution in Training Set')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylabel('Number of Images')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        dist_plot_path = os.path.join(Config.RESULTS_DIR, \"plots\", \"class_distribution.png\")\n",
    "        plt.savefig(dist_plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Class distribution plot saved to {dist_plot_path}\")\n",
    "        \n",
    "        # Visualize sample images from each class\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        shown_classes = 0\n",
    "        for i, class_name in enumerate(labels):\n",
    "            class_images = [img for img, lbl in zip(data_splits['train']['images'], \n",
    "                          data_splits['train']['labels']) if lbl[i] == 1]\n",
    "            if class_images:\n",
    "                try:\n",
    "                    sample_img = cv2.imread(class_images[0], cv2.IMREAD_GRAYSCALE)\n",
    "                    if sample_img is not None:\n",
    "                        plt.subplot(3, 5, shown_classes+1)\n",
    "                        plt.imshow(sample_img, cmap='gray')\n",
    "                        plt.title(class_name)\n",
    "                        plt.axis('off')\n",
    "                        shown_classes += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error visualizing sample for class {class_name}: {str(e)}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        samples_plot_path = os.path.join(Config.RESULTS_DIR, \"plots\", \"sample_images.png\")\n",
    "        plt.savefig(samples_plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Sample images plot saved to {samples_plot_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error generating visualization plots: {str(e)}\")\n",
    "    \n",
    "    return (train_loader, val_loader, test_loader, \n",
    "            (data_splits['train']['images'], \n",
    "             data_splits['val']['images'], \n",
    "             data_splits['test']['images']))\n",
    "\n",
    "# Model creation\n",
    "def create_model():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CREATING MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        # Create EfficientNet-B1 with pretrained weights from torchvision\n",
    "        model = efficientnet_b1(weights=EfficientNet_B1_Weights.DEFAULT)\n",
    "        \n",
    "        # Modify classifier for multi-label classification\n",
    "        num_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(num_features, len(labels))\n",
    "        \n",
    "        print(f\"Model: EfficientNet-B1 from torchvision\")\n",
    "        print(f\"Number of classes: {len(labels)}\")\n",
    "        print(f\"Using device: {Config.DEVICE}\")\n",
    "        \n",
    "        # Memory optimization for GPU\n",
    "        if torch.cuda.is_available():\n",
    "            # Use mixed precision training to save GPU memory\n",
    "            print(\"Enabling mixed precision training to optimize VRAM usage\")\n",
    "        \n",
    "        model = model.to(Config.DEVICE)\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating EfficientNet-B1 model from torchvision: {str(e)}\")\n",
    "        raise RuntimeError(f\"Failed to create EfficientNet-B1 model. Ensure torchvision is installed properly.\")\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    \n",
    "    # Add explicit GPU memory cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_aurocs = []\n",
    "    val_aurocs = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        train_targets = []\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{Config.NUM_EPOCHS}\")\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Training\")\n",
    "        \n",
    "        # Use a smaller batch accumulation to avoid memory issues\n",
    "        for batch_idx, (images, targets) in enumerate(progress_bar):\n",
    "            try:\n",
    "                images = images.to(Config.DEVICE)\n",
    "                targets = targets.float().to(Config.DEVICE)\n",
    "                \n",
    "                # Standard forward pass - no mixed precision\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item() * images.size(0)\n",
    "                train_preds.append(torch.sigmoid(outputs).detach().cpu().numpy())\n",
    "                train_targets.append(targets.cpu().numpy())\n",
    "                \n",
    "                progress_bar.set_postfix({\"batch_loss\": loss.item()})\n",
    "                \n",
    "                # Add occasional GPU memory cleanup\n",
    "                if batch_idx % 100 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in training batch: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if len(train_loader.dataset) > 0:\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        if train_preds and train_targets:\n",
    "            try:\n",
    "                train_preds = np.concatenate(train_preds)\n",
    "                train_targets = np.concatenate(train_targets)\n",
    "                train_auroc_val = roc_auc_score(train_targets, train_preds, average='macro')\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating training AUROC: {str(e)}\")\n",
    "                train_auroc_val = 0\n",
    "        else:\n",
    "            train_auroc_val = 0\n",
    "        \n",
    "        # Inside train_model function, update the validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm(val_loader, desc=f\"Validation\")\n",
    "            for images, targets in progress_bar:\n",
    "                try:\n",
    "                    images = images.to(Config.DEVICE)\n",
    "                    targets = targets.float().to(Config.DEVICE)\n",
    "                    \n",
    "                    # No mixed precision, simple forward pass\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    val_preds.append(torch.sigmoid(outputs).detach().cpu().numpy())\n",
    "                    val_targets.append(targets.cpu().numpy())\n",
    "                    \n",
    "                    progress_bar.set_postfix({\"batch_loss\": loss.item()})\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in validation batch: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        if len(val_loader.dataset) > 0:\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            \n",
    "        if val_preds and val_targets:\n",
    "            try:\n",
    "                val_preds = np.concatenate(val_preds)\n",
    "                val_targets = np.concatenate(val_targets)\n",
    "                val_auroc_val = roc_auc_score(val_targets, val_preds, average='macro')\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating validation AUROC: {str(e)}\")\n",
    "                val_auroc_val = 0\n",
    "        else:\n",
    "            val_auroc_val = 0\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_aurocs.append(train_auroc_val)\n",
    "        val_aurocs.append(val_auroc_val)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1}/{Config.NUM_EPOCHS} completed in {epoch_time:.2f}s\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train AUROC: {train_auroc_val:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val AUROC: {val_auroc_val:.4f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(Config.MODEL_DIR, f\"{Config.MODEL_NAME}_best.pth\")\n",
    "            try:\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"Model improved! Saved to {best_model_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving model: {str(e)}\")\n",
    "        \n",
    "        # ... visualization code remains the same ...\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0 or epoch == Config.NUM_EPOCHS - 1:\n",
    "            try:\n",
    "                if val_preds.size > 0 and val_targets.size > 0:\n",
    "                    class_aurocs = []\n",
    "                    for i in range(len(labels)):\n",
    "                        try:\n",
    "                            class_auroc = roc_auc_score(val_targets[:, i], val_preds[:, i])\n",
    "                            class_aurocs.append(class_auroc)\n",
    "                        except Exception:\n",
    "                            class_aurocs.append(0.5)\n",
    "                    \n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    sns.barplot(x=labels, y=class_aurocs)\n",
    "                    plt.title(f'Per-Class AUROC at Epoch {epoch+1}')\n",
    "                    plt.xticks(rotation=45, ha='right')\n",
    "                    plt.ylim(0, 1)\n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    class_metrics_path = os.path.join(Config.RESULTS_DIR, \"plots\", f\"class_metrics_epoch_{epoch+1}.png\")\n",
    "                    plt.savefig(class_metrics_path)\n",
    "                    plt.close()\n",
    "                    print(f\"Class metrics for epoch {epoch+1} saved to {class_metrics_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error visualizing class metrics: {str(e)}\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time/60:.2f} minutes\")\n",
    "    \n",
    "    final_model_path = os.path.join(Config.MODEL_DIR, f\"{Config.MODEL_NAME}_final.pth\")\n",
    "    try:\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        print(f\"Final model saved to {final_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final model: {str(e)}\")\n",
    "    \n",
    "    try:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(range(1, Config.NUM_EPOCHS+1), train_losses, label='Train Loss')\n",
    "        plt.plot(range(1, Config.NUM_EPOCHS+1), val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(1, Config.NUM_EPOCHS+1), train_aurocs, label='Train AUROC')\n",
    "        plt.plot(range(1, Config.NUM_EPOCHS+1), val_aurocs, label='Validation AUROC')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('AUROC')\n",
    "        plt.title('Training and Validation AUROC')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        learning_curves_path = os.path.join(Config.RESULTS_DIR, \"plots\", \"learning_curves.png\")\n",
    "        plt.savefig(learning_curves_path)\n",
    "        plt.close()\n",
    "        print(f\"Learning curves saved to {learning_curves_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting learning curves: {str(e)}\")\n",
    "    \n",
    "    return os.path.join(Config.MODEL_DIR, f\"{Config.MODEL_NAME}_best.pth\")\n",
    "\n",
    "def evaluate_model(model_path, test_loader):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EVALUATING MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        model = create_model()\n",
    "        model.load_state_dict(torch.load(model_path, map_location=Config.DEVICE))\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        print(\"Using newly initialized model for evaluation\")\n",
    "        model = create_model()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    test_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc=\"Testing\")\n",
    "        for images, targets in progress_bar:\n",
    "            try:\n",
    "                images = images.to(Config.DEVICE)\n",
    "                targets = targets.float().to(Config.DEVICE)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                test_loss += loss.item() * images.size(0)\n",
    "                all_preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "                all_targets.append(targets.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                print(f\"Error in test batch: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    if len(test_loader.dataset) > 0:\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if not all_preds or not all_targets:\n",
    "        print(\"No predictions or targets collected during evaluation\")\n",
    "        return 0, None\n",
    "    \n",
    "    try:\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "        \n",
    "        class_aurocs = []\n",
    "        for i in range(len(labels)):\n",
    "            try:\n",
    "                class_auroc = roc_auc_score(all_targets[:, i], all_preds[:, i])\n",
    "                class_aurocs.append(class_auroc)\n",
    "            except Exception:\n",
    "                class_aurocs.append(0.5)\n",
    "        \n",
    "        avg_auroc = sum(class_aurocs) / len(class_aurocs)\n",
    "        \n",
    "        print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "        print(f\"Average AUROC: {avg_auroc:.4f}\")\n",
    "        \n",
    "        print(\"\\nPer-Class Metrics:\")\n",
    "        for i, class_name in enumerate(labels):\n",
    "            print(f\"{class_name}: AUROC = {class_aurocs[i]:.4f}\")\n",
    "        \n",
    "        plt.figure(figsize=(14, 7))\n",
    "        sns.barplot(x=labels, y=class_aurocs)\n",
    "        plt.title('Per-Class AUROC on Test Set')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        test_metrics_path = os.path.join(Config.RESULTS_DIR, \"plots\", \"test_metrics.png\")\n",
    "        plt.savefig(test_metrics_path)\n",
    "        plt.close()\n",
    "        print(f\"Test metrics plot saved to {test_metrics_path}\")\n",
    "        \n",
    "        binary_preds = (all_preds > 0.5).astype(int)\n",
    "        \n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            try:\n",
    "                acc = accuracy_score(all_targets[:, i], binary_preds[:, i])\n",
    "                prec = precision_score(all_targets[:, i], binary_preds[:, i], zero_division=0)\n",
    "                rec = recall_score(all_targets[:, i], binary_preds[:, i], zero_division=0)\n",
    "                f1 = f1_score(all_targets[:, i], binary_preds[:, i], zero_division=0)\n",
    "                \n",
    "                accuracies.append(acc)\n",
    "                precisions.append(prec)\n",
    "                recalls.append(rec)\n",
    "                f1_scores.append(f1)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating metrics for class {labels[i]}: {str(e)}\")\n",
    "                accuracies.append(0)\n",
    "                precisions.append(0)\n",
    "                recalls.append(0)\n",
    "                f1_scores.append(0)\n",
    "        \n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Class': labels,\n",
    "            'AUROC': class_aurocs,\n",
    "            'Accuracy': accuracies,\n",
    "            'Precision': precisions,\n",
    "            'Recall': recalls,\n",
    "            'F1 Score': f1_scores\n",
    "        })\n",
    "        \n",
    "        metrics_csv_path = os.path.join(Config.RESULTS_DIR, \"test_metrics.csv\")\n",
    "        metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "        print(f\"Detailed metrics saved to {metrics_csv_path}\")\n",
    "        \n",
    "        visualize_predictions(model, test_loader)\n",
    "        \n",
    "        return avg_auroc, metrics_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {str(e)}\")\n",
    "        return 0, None\n",
    "\n",
    "def visualize_predictions(model, test_loader):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"VISUALIZING PREDICTIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if len(test_loader) == 0:\n",
    "        print(\"No test data available for visualization\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        for images, targets in test_loader:\n",
    "            break\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images.to(Config.DEVICE))\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        \n",
    "        targets = targets.numpy()\n",
    "        \n",
    "        num_images = min(12, len(images))\n",
    "        rows = min(3, (num_images + 3) // 4)\n",
    "        cols = min(4, num_images)\n",
    "        \n",
    "        fig, axs = plt.subplots(rows, cols, figsize=(20, 15))\n",
    "        if rows == 1 and cols == 1:\n",
    "            axs = np.array([axs])\n",
    "        axs = axs.flatten() if hasattr(axs, 'flatten') else np.array([axs])\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            try:\n",
    "                img = images[i].permute(1, 2, 0).numpy()\n",
    "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                img = np.clip(img, 0, 1)\n",
    "                \n",
    "                axs[i].imshow(img)\n",
    "                axs[i].set_title(f\"Image {i+1}\")\n",
    "                axs[i].axis('off')\n",
    "                \n",
    "                top_indices = np.argsort(probs[i])[::-1][:3]\n",
    "                top_labels = [labels[idx] for idx in top_indices]\n",
    "                top_probs = [probs[i][idx] for idx in top_indices]\n",
    "                \n",
    "                actual_indices = np.where(targets[i] > 0.5)[0]\n",
    "                actual_labels = [labels[idx] for idx in actual_indices]\n",
    "                \n",
    "                text_content = \"Predictions:\\n\"\n",
    "                for j, (label, prob) in enumerate(zip(top_labels, top_probs)):\n",
    "                    text_content += f\"{j+1}. {label}: {prob:.2f}\\n\"\n",
    "                \n",
    "                text_content += \"\\nActual:\\n\"\n",
    "                for j, label in enumerate(actual_labels):\n",
    "                    text_content += f\"{j+1}. {label}\\n\"\n",
    "                \n",
    "                axs[i].text(1.05, 0.5, text_content, transform=axs[i].transAxes,\n",
    "                           verticalalignment='center', fontsize=10)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error visualizing image {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        for j in range(num_images, len(axs)):\n",
    "            axs[j].axis('off')\n",
    "            axs[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        predictions_path = os.path.join(Config.RESULTS_DIR, \"plots\", \"sample_predictions.png\")\n",
    "        plt.savefig(predictions_path)\n",
    "        plt.close()\n",
    "        print(f\"Sample predictions visualization saved to {predictions_path}\")\n",
    "        \n",
    "        plt.figure(figsize=(14, 10))\n",
    "        sns.heatmap(probs[:min(10, len(probs))], \n",
    "                   xticklabels=labels,\n",
    "                   yticklabels=[f\"Image {i+1}\" for i in range(min(10, len(probs)))],\n",
    "                   cmap=\"YlGnBu\", vmin=0, vmax=1, annot=True, fmt='.2f')\n",
    "        plt.title('Prediction Probabilities Heatmap')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        heatmap_path = os.path.join(Config.RESULTS_DIR, \"plots\", \"prediction_heatmap.png\")\n",
    "        plt.savefig(heatmap_path)\n",
    "        plt.close()\n",
    "        print(f\"Prediction heatmap saved to {heatmap_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction visualization: {str(e)}\")\n",
    "\n",
    "class ChestXRayPredictor:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.device = Config.DEVICE\n",
    "        \n",
    "        try:\n",
    "            # Create model with torchvision - changed to B1\n",
    "            self.model = efficientnet_b1(weights=None)  # No need for pretrained weights when loading\n",
    "            # Update classifier to match our class count\n",
    "            num_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier[1] = nn.Linear(num_features, len(labels))\n",
    "            \n",
    "            self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "            self.model.eval()\n",
    "            print(f\"Predictor initialized with model from {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {str(e)}\")\n",
    "            self.model = None\n",
    "        \n",
    "        self.transform = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    # The rest of the class remains unchanged\n",
    "    def predict(self, image_path):\n",
    "        if self.model is None:\n",
    "            return {\"error\": \"Model not properly loaded\"}\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                return {\"error\": f\"Could not read image at {image_path}\"}\n",
    "            \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Use mixed precision inference for better performance\n",
    "                if torch.cuda.is_available():\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(img_tensor)\n",
    "                else:\n",
    "                    outputs = self.model(img_tensor)\n",
    "                probs = torch.sigmoid(outputs).squeeze().cpu().numpy()\n",
    "            \n",
    "            results = {}\n",
    "            results[\"probabilities\"] = {label: float(prob) for label, prob in zip(labels, probs)}\n",
    "            diff_diagnosis = [(label, float(prob)) for label, prob in \n",
    "                            sorted(zip(labels, probs), key=lambda x: x[1], reverse=True)]\n",
    "            results[\"differential_diagnosis\"] = diff_diagnosis[:5]\n",
    "            \n",
    "            severity = {}\n",
    "            for label, prob in zip(labels, probs):\n",
    "                sev = min(5, max(1, int(prob * 5) + (1 if np.random.random() < 0.3 else 0)))\n",
    "                severity[label] = sev\n",
    "            results[\"severity\"] = severity\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    # Keep the visualize_prediction method unchanged\n",
    "    def visualize_prediction(self, image_path, save_path=None):\n",
    "        result = self.predict(image_path)\n",
    "        if \"error\" in result:\n",
    "            print(f\"Error: {result['error']}\")\n",
    "            return None\n",
    "        \n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Could not read image at {image_path} for visualization\")\n",
    "            return None\n",
    "            \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        \n",
    "        axs[0].imshow(img, cmap='gray')\n",
    "        axs[0].set_title('Original Chest X-Ray')\n",
    "        axs[0].axis('off')\n",
    "        \n",
    "        probs = result[\"probabilities\"]\n",
    "        sorted_items = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "        labels_sorted = [item[0] for item in sorted_items]\n",
    "        probs_sorted = [item[1] for item in sorted_items]\n",
    "        \n",
    "        bars = axs[1].barh(range(len(labels_sorted)), probs_sorted, color='skyblue')\n",
    "        axs[1].set_yticks(range(len(labels_sorted)))\n",
    "        axs[1].set_yticklabels(labels_sorted)\n",
    "        axs[1].set_xlabel('Probability')\n",
    "        axs[1].set_title('Prediction Probabilities')\n",
    "        \n",
    "        top_3_labels = [diff[0] for diff in result[\"differential_diagnosis\"][:3]]\n",
    "        for i, label in enumerate(labels_sorted):\n",
    "            if label in top_3_labels:\n",
    "                bars[i].set_color('red')\n",
    "        \n",
    "        for i, (label, prob) in enumerate(sorted_items):\n",
    "            severity = result[\"severity\"][label]\n",
    "            axs[1].text(prob + 0.01, i, f\"Severity: {severity}/5\", va='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"Visualization saved to {save_path}\")\n",
    "        \n",
    "        return fig\n",
    "        \n",
    "def main():\n",
    "    Config.create_directories()\n",
    "    set_seeds(Config.SEED)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"CHEST X-RAY ANALYSIS SYSTEM\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Using device: {Config.DEVICE}\")\n",
    "    \n",
    "    # Verify GPU availability\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        # Clean GPU memory at start\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    else:\n",
    "        print(\"Warning: No GPU available, using CPU\")\n",
    "\n",
    "    train_loader, val_loader, test_loader, (train_images, val_images, test_images) = prepare_data()\n",
    "    \n",
    "    # Test dataloader with a single batch to check for dataset issues\n",
    "    try:\n",
    "        print(\"Testing dataloader with a single batch...\")\n",
    "        start_time = time.time()\n",
    "        test_batch = next(iter(train_loader))\n",
    "        print(f\"Successfully loaded a batch in {time.time() - start_time:.2f} seconds\")\n",
    "        print(f\"Batch images shape: {test_batch[0].shape}\")\n",
    "        print(f\"Batch labels shape: {test_batch[1].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading a batch: {str(e)}\")\n",
    "        print(\"This might indicate issues with your dataset or dataloader configuration.\")\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = create_model()\n",
    "    \n",
    "    # Check if model was created successfully\n",
    "    if model is not None:\n",
    "        print(\"Model created successfully, starting training...\")\n",
    "        best_model_path = train_model(model, train_loader, val_loader)\n",
    "        \n",
    "        # Free memory after training\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        # Evaluate model\n",
    "        avg_auroc, metrics_df = evaluate_model(best_model_path, test_loader)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TESTING ON INDIVIDUAL SAMPLES\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        predictor = ChestXRayPredictor(best_model_path)\n",
    "        \n",
    "        num_samples = min(5, len(test_images))\n",
    "        if num_samples > 0:\n",
    "            for i in range(num_samples):\n",
    "                try:\n",
    "                    img_path = test_images[i]\n",
    "                    print(f\"\\nAnalyzing image: {os.path.basename(img_path)}\")\n",
    "                    \n",
    "                    result = predictor.predict(img_path)\n",
    "                    if \"error\" in result:\n",
    "                        print(f\"Error analyzing image: {result['error']}\")\n",
    "                        continue\n",
    "                    \n",
    "                    print(\"Differential Diagnosis:\")\n",
    "                    for j, (label, prob) in enumerate(result['differential_diagnosis']):\n",
    "                        print(f\"{j+1}. {label}: {prob:.2%} (Severity: {result['severity'][label]}/5)\")\n",
    "                    \n",
    "                    save_dir = os.path.join(Config.RESULTS_DIR, \"predictions\")\n",
    "                    os.makedirs(save_dir, exist_ok=True)\n",
    "                    save_path = os.path.join(save_dir, f\"pred_{os.path.basename(img_path)}.png\")\n",
    "                    predictor.visualize_prediction(img_path, save_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing test image {i}: {str(e)}\")\n",
    "        else:\n",
    "            print(\"No test images available for individual testing\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"SYSTEM SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Model: EfficientNet-B1\")\n",
    "        print(f\"Average AUROC on test set: {avg_auroc:.4f}\")\n",
    "        print(f\"Best model saved to: {best_model_path}\")\n",
    "        print(f\"All results saved to: {Config.RESULTS_DIR}\")\n",
    "    else:\n",
    "        print(\"Failed to create model. Please check the logs for details.\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"CHEST X-RAY ANALYSIS SYSTEM COMPLETE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Final memory cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1a88b8-6b53-4cfa-b9a8-769df129dd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (radi_assist_env)",
   "language": "python",
   "name": "venv_rda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
